# download_nllb_model.py
# NLLB ëª¨ë¸ì„ ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from pathlib import Path
import os
from tqdm import tqdm

def download_nllb_model():
    """NLLB ëª¨ë¸ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ"""
    
    # ëª¨ë¸ ì •ë³´
    model_name = "facebook/nllb-200-distilled-600M"
    local_dir = "./models/nllb-200-distilled-600M"
    
    print(f"ğŸš€ NLLB ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {model_name}")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {local_dir}")
    print(f"ğŸ“Š ì˜ˆìƒ í¬ê¸°: ì•½ 2.4GB")
    print("-" * 50)
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    Path(local_dir).mkdir(parents=True, exist_ok=True)
    
    try:
        # 1. í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ
        print("1ï¸âƒ£ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì¤‘...")
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            cache_dir=local_dir,
            local_files_only=False,
            force_download=False  # ì´ë¯¸ ìˆìœ¼ë©´ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•˜ì§€ ì•ŠìŒ
        )
        print("âœ… í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        
        # 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        print("2ï¸âƒ£ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        model = AutoModelForSeq2SeqLM.from_pretrained(
            model_name,
            cache_dir=local_dir,
            local_files_only=False,
            force_download=False,
            torch_dtype='auto'
        )
        print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        
        # 3. ë¡œì»¬ì— ì €ì¥
        print("3ï¸âƒ£ ë¡œì»¬ì— ì €ì¥ ì¤‘...")
        tokenizer.save_pretrained(local_dir)
        model.save_pretrained(local_dir)
        print("âœ… ë¡œì»¬ ì €ì¥ ì™„ë£Œ!")
        
        # 4. ë‹¤ìš´ë¡œë“œ í™•ì¸
        print("4ï¸âƒ£ ë‹¤ìš´ë¡œë“œ íŒŒì¼ í™•ì¸...")
        files_to_check = [
            "config.json",
            "tokenizer.json", 
            "tokenizer_config.json",
            "special_tokens_map.json"
        ]
        
        for filename in files_to_check:
            filepath = Path(local_dir) / filename
            if filepath.exists():
                print(f"   âœ… {filename}")
            else:
                print(f"   âŒ {filename} (ëˆ„ë½)")
        
        # ëª¨ë¸ íŒŒì¼ í™•ì¸ (pytorch_model.bin ë˜ëŠ” model.safetensors)
        model_files = list(Path(local_dir).glob("pytorch_model*.bin")) + \
                     list(Path(local_dir).glob("model*.safetensors"))
        
        if model_files:
            for model_file in model_files:
                size_mb = model_file.stat().st_size / (1024 * 1024)
                print(f"   âœ… {model_file.name} ({size_mb:.1f}MB)")
        else:
            print("   âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            
        print("-" * 50)
        print("ğŸ‰ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ“ ëª¨ë¸ ìœ„ì¹˜: {os.path.abspath(local_dir)}")
        
        return local_dir
        
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def test_model(model_path):
    """ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    try:
        from transformers import pipeline
        
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        translator = pipeline(
            "translation",
            model=model_path,
            tokenizer=model_path,
            device=-1  # CPU ì‚¬ìš©
        )
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        test_text = "Hello, how are you?"
        result = translator(
            test_text, 
            src_lang="eng_Latn", 
            tgt_lang="kor_Hang",
            max_length=100
        )
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"   ì…ë ¥: {test_text}")
        print(f"   ì¶œë ¥: {result[0]['translation_text']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¤– NLLB ëª¨ë¸ ë‹¤ìš´ë¡œë”")
    print("=" * 60)
    
    # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
    model_path = download_nllb_model()
    
    if model_path:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_success = test_model(model_path)
        
        if test_success:
            print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
            print("1. translator.pyì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•˜ì„¸ìš”:")
            print(f'   model_path = r"{os.path.abspath(model_path)}"')
            print("2. í”„ë¡œê·¸ë¨ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        else:
            print("\nâš ï¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. HuggingFace ìë™ ë‹¤ìš´ë¡œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    else:
        print("\nâŒ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ëŒ€ì•ˆ: ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    
    print("\n" + "=" * 60)
    input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")